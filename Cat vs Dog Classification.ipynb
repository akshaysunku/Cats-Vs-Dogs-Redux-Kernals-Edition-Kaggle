{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Solution\n",
    "# Dogs vs. Cats Redux: Kernels Edition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will be going to perform classification of Dogs and Cats images. </br>\n",
    "We have been provided with 25,000 images of training data and 12,500 images of test data. For each image in the test set, you should predict a probability that the image is a dog (1 = dog, 0 = cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from random import shuffle\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'E:/Kaggle/dogs-vs-cats/train/train'         # path to the folder containig train images\n",
    "TEST_DIR = 'E:/Kaggle/dogs-vs-cats/test/test'            # path to the folder containig test images\n",
    "\n",
    "IMG_SIZE = 150                                           # image pixel size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to get the labels of the images for training as the labels are not directly provided, we get the labels using the \n",
    "<i>image_name</i>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns 0 if the image is cat and returns 1 if dog.\n",
    "def image_label(img):\n",
    "    label = img.split('.')[-3]\n",
    "    if label == 'cat':\n",
    "        return 0\n",
    "    elif label == 'dog':\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images have to be represented in numbers. This is performed by using the <b>OpenCV</b> library to read and then resizing the image to <b>IMG_SIZE</b>. <br>\n",
    "This is done for both the traning and test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data():\n",
    "    training_data = []\n",
    "    training_labels = []\n",
    "    img_paths = os.listdir(TRAIN_DIR)\n",
    "    shuffle(img_paths)\n",
    "    for img in img_paths:\n",
    "        label = image_label(img)\n",
    "        path = os.path.join(TRAIN_DIR, img)\n",
    "        img = cv2.resize(cv2.imread(path), (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_CUBIC)\n",
    "        training_data.append(img)\n",
    "        training_labels.append(label)\n",
    "    \n",
    "    return training_data, training_labels   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_testing_data():\n",
    "    testing_data = []\n",
    "    testing_num = []\n",
    "    for img in os.listdir(TEST_DIR):\n",
    "        img_num = img.split('.')[0]\n",
    "        path = os.path.join(TEST_DIR, img)\n",
    "        img = cv2.resize(cv2.imread(path), (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_CUBIC)\n",
    "        testing_data.append(img)\n",
    "        testing_num.append(img_num)\n",
    "\n",
    "    return testing_data, testing_num    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = create_training_data() \n",
    "test_data, test_num = create_testing_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data is divided into training and validation data for validating the performance of the model and finally use the \n",
    "best model on the test set. <br>\n",
    "\n",
    "20,000 images are used for training and 5,000 images are used for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array(train_data[:-5000])\n",
    "train_y = np.array(train_labels[:-5000])\n",
    "\n",
    "val_x = np.array(train_data[-5000:])\n",
    "val_y = np.array(train_labels[-5000:])\n",
    "\n",
    "test_x = np.array(test_data) / 255\n",
    "test_y = np.array(test_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the Sequential model from the keras library to build the Convolutional Neural Network(CNN). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Akshay Sunku\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                1183808   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,212,513\n",
      "Trainable params: 1,212,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare generators for training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_generator = train_datagen.flow(train_x, train_y, batch_size=batch_size)\n",
    "validation_generator = val_datagen.flow(val_x, val_y, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its now time to start training the model!!! <br>\n",
    "\n",
    "I have initially ran the model for 15 epochs and found that the model was overfitting after 8 epochs, so I have used 8 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Akshay Sunku\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/8\n",
      "1250/1250 [==============================] - 614s 491ms/step - loss: 0.6275 - acc: 0.6478 - val_loss: 0.6075 - val_acc: 0.7037\n",
      "Epoch 2/8\n",
      "1250/1250 [==============================] - 568s 454ms/step - loss: 0.5270 - acc: 0.7421 - val_loss: 0.4635 - val_acc: 0.7817\n",
      "Epoch 3/8\n",
      "1250/1250 [==============================] - 562s 450ms/step - loss: 0.4842 - acc: 0.7723 - val_loss: 0.4524 - val_acc: 0.7869\n",
      "Epoch 4/8\n",
      "1250/1250 [==============================] - 562s 450ms/step - loss: 0.4549 - acc: 0.7922 - val_loss: 0.4841 - val_acc: 0.7681\n",
      "Epoch 5/8\n",
      "1250/1250 [==============================] - 563s 451ms/step - loss: 0.4335 - acc: 0.8101 - val_loss: 0.4036 - val_acc: 0.8218\n",
      "Epoch 6/8\n",
      "1250/1250 [==============================] - 570s 456ms/step - loss: 0.4186 - acc: 0.8147 - val_loss: 0.3920 - val_acc: 0.8232\n",
      "Epoch 7/8\n",
      "1250/1250 [==============================] - 565s 452ms/step - loss: 0.3974 - acc: 0.8269 - val_loss: 0.4018 - val_acc: 0.8270\n",
      "Epoch 8/8\n",
      "1250/1250 [==============================] - 561s 449ms/step - loss: 0.3940 - acc: 0.8312 - val_loss: 0.3919 - val_acc: 0.8285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f338673390>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator, \n",
    "    steps_per_epoch=len(train_x) // batch_size,\n",
    "    epochs=8,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(val_x) // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the accuracy on the training set is 83% and accuracy on the test set is also close to 83%, which is a good \n",
    "accuracy for such a small trainig set. <br>\n",
    "\n",
    "Now we finally use the trained model to predict on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 94s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_x, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = range(1, len(test_x) + 1)\n",
    "result = pd.DataFrame({\"id\": ids, \"label\":list(predictions)})\n",
    "cols = ['label']\n",
    "\n",
    "for col in cols:\n",
    "    result[col] = result[col].map(lambda x: str(x).lstrip('[').rstrip(']')).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the results into a csv for submission to Kaggle!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"dogs_vs_cats.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
